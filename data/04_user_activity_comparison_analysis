# === ç”¨æˆ·æ´»è·ƒåº¦å¯¹æ¯”åˆ†æ ===
def user_activity_comparison():
    """
    å¯¹æ¯”é«˜æ´»è·ƒvsä½æ´»è·ƒç”¨æˆ·çš„è¡Œä¸ºå·®å¼‚
    è¿™æ˜¯é‡è¦çš„ç»†åˆ†åˆ†æ
    """
    
    print("=== ç”¨æˆ·æ´»è·ƒåº¦å¯¹æ¯”åˆ†æ ===")
    
    try:
        # åŠ è½½æ—¶åºæ•°æ®
        print("1. åŠ è½½æ•°æ®...")
        df_ts = pd.read_parquet('data_multi_users_timeseries.parquet')
        
        # è®¡ç®—æ¯ä¸ªç”¨æˆ·çš„è¯„è®ºæ•°
        user_review_counts = df_ts.groupby('user_id').size()
        
        # å®šä¹‰æ´»è·ƒåº¦
        high_active_users = user_review_counts[user_review_counts >= 5].index  # 5æ¡ä»¥ä¸Š
        low_active_users = user_review_counts[user_review_counts < 5].index    # 5æ¡ä»¥ä¸‹
        
        print(f"   é«˜æ´»è·ƒç”¨æˆ·: {len(high_active_users):,}")
        print(f"   ä½æ´»è·ƒç”¨æˆ·: {len(low_active_users):,}")
        
        # åˆ†åˆ«åˆ†æä¸¤ç»„ç”¨æˆ·
        high_active_data = df_ts[df_ts['user_id'].isin(high_active_users)]
        low_active_data = df_ts[df_ts['user_id'].isin(low_active_users)]
        
        print(f"   é«˜æ´»è·ƒç”¨æˆ·è®°å½•: {len(high_active_data):,}")
        print(f"   ä½æ´»è·ƒç”¨æˆ·è®°å½•: {len(low_active_data):,}")
        
        # 2. å¯¹æ¯”åˆ†æ
        print("\n2. å¯¹æ¯”åˆ†æ...")
        
        def analyze_group(data, group_name):
            """åˆ†æç”¨æˆ·ç»„çš„ç‰¹å¾"""
            results = {}
            
            # åŸºç¡€ç»Ÿè®¡
            results['avg_sentiment'] = data['sentiment'].mean()
            results['avg_rating'] = data['rating'].mean()
            results['sentiment_std'] = data['sentiment'].std()
            
            # å˜åŒ–åˆ†æ
            changes = data['sentiment_change'].dropna()
            if len(changes) > 0:
                results['sentiment_change_mean'] = changes.mean()
                results['sentiment_change_std'] = changes.std()
                results['positive_change_pct'] = (changes > 0).mean() * 100
            
            rating_changes = data['rating_change'].dropna()
            if len(rating_changes) > 0:
                results['rating_change_mean'] = rating_changes.mean()
                results['positive_rating_change_pct'] = (rating_changes > 0).mean() * 100
            
            return results
        
        # åˆ†æä¸¤ç»„
        high_active_results = analyze_group(high_active_data, "é«˜æ´»è·ƒ")
        low_active_results = analyze_group(low_active_data, "ä½æ´»è·ƒ")
        
        print("   å¯¹æ¯”ç»“æœ:")
        metrics = ['avg_sentiment', 'avg_rating', 'sentiment_std', 
                  'sentiment_change_mean', 'positive_change_pct']
        
        for metric in metrics:
            if metric in high_active_results and metric in low_active_results:
                high_val = high_active_results[metric]
                low_val = low_active_results[metric]
                diff = high_val - low_val
                print(f"     {metric}:")
                print(f"       é«˜æ´»è·ƒ: {high_val:.3f}")
                print(f"       ä½æ´»è·ƒ: {low_val:.3f}")
                print(f"       å·®å¼‚: {diff:.3f}")
        
        # 3. å‡è®¾H2éªŒè¯ï¼šæƒ…ç»ªæ³¢åŠ¨ä¸æ´»è·ƒåº¦å…³ç³»
        print("\n3. H2éªŒè¯ï¼šæƒ…ç»ªæ³¢åŠ¨ä¸ç”¨æˆ·æ´»è·ƒåº¦...")
        
        # è®¡ç®—ç”¨æˆ·çº§åˆ«çš„æ³¢åŠ¨æ€§
        user_volatility_high = []
        user_volatility_low = []
        
        # é‡‡æ ·åˆ†æï¼ˆé¿å…å†…å­˜é—®é¢˜ï¼‰
        sample_high = list(high_active_users)[:200] if len(high_active_users) > 200 else list(high_active_users)
        sample_low = list(low_active_users)[:500] if len(low_active_users) > 500 else list(low_active_users)
        
        for user_id in sample_high:
            user_data = df_ts[df_ts['user_id'] == user_id]
            if len(user_data) > 2:
                volatility = user_data['sentiment'].std()
                if not pd.isna(volatility):
                    user_volatility_high.append(volatility)
        
        for user_id in sample_low:
            user_data = df_ts[df_ts['user_id'] == user_id]
            if len(user_data) > 1:
                volatility = user_data['sentiment'].std()
                if not pd.isna(volatility):
                    user_volatility_low.append(volatility)
        
        if user_volatility_high and user_volatility_low:
            avg_vol_high = sum(user_volatility_high) / len(user_volatility_high)
            avg_vol_low = sum(user_volatility_low) / len(user_volatility_low)
            
            print(f"     é«˜æ´»è·ƒç”¨æˆ·å¹³å‡æ³¢åŠ¨æ€§: {avg_vol_high:.3f}")
            print(f"     ä½æ´»è·ƒç”¨æˆ·å¹³å‡æ³¢åŠ¨æ€§: {avg_vol_low:.3f}")
            print(f"     æ³¢åŠ¨æ€§å·®å¼‚: {avg_vol_high - avg_vol_low:.3f}")
            
            if avg_vol_high < avg_vol_low:
                print("     ğŸ“Š å‘ç°ï¼šé«˜æ´»è·ƒç”¨æˆ·æƒ…ç»ªæ›´ç¨³å®šï¼")
            else:
                print("     ğŸ“Š å‘ç°ï¼šé«˜æ´»è·ƒç”¨æˆ·æƒ…ç»ªæ³¢åŠ¨æ›´å¤§")
        
        # ä¿å­˜å¯¹æ¯”ç»“æœ
        comparison_results = {
            'high_active_stats': high_active_results,
            'low_active_stats': low_active_results,
            'volatility_analysis': {
                'high_active_volatility': avg_vol_high if 'avg_vol_high' in locals() else None,
                'low_active_volatility': avg_vol_low if 'avg_vol_low' in locals() else None
            },
            'sample_sizes': {
                'high_active_users': len(high_active_users),
                'low_active_users': len(low_active_users)
            }
        }
        
        import json
        with open('user_activity_comparison.json', 'w') as f:
            json.dump(comparison_results, f, indent=2, default=str)
        
        print(f"\nâœ… ç”¨æˆ·æ´»è·ƒåº¦å¯¹æ¯”åˆ†æå®Œæˆï¼")
        return comparison_results
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return None

# æ‰§è¡Œå¯¹æ¯”åˆ†æ
comparison_results = user_activity_comparison()
