# === 3️⃣ 改进版用户聚类分析 ===
def advanced_user_clustering():
    """
    改进版用户聚类分析
    基于多维特征进行用户分群
    """
    
    print("=== 改进版用户聚类分析 ===")
    
    try:
        # 加载数据
        df_ts = pd.read_parquet('data_multi_users_timeseries.parquet')
        
        # 构建用户特征矩阵
        print("1. 构建用户特征矩阵...")
        
        user_features = {}
        sample_users = df_ts['user_id'].unique()[:800]  # 800用户分析
        
        for user_id in sample_users:
            user_data = df_ts[df_ts['user_id'] == user_id]
            
            if len(user_data) >= 2:
                # 基础统计特征
                sentiments = user_data['sentiment'].dropna().tolist()
                ratings = user_data['rating'].dropna().tolist()
                
                if len(sentiments) > 0 and len(ratings) > 0:
                    # 计算特征
                    features = {
                        'avg_sentiment': sum(sentiments) / len(sentiments),
                        'sentiment_volatility': calculate_std(sentiments),
                        'avg_rating': sum(ratings) / len(ratings),
                        'rating_volatility': calculate_std(ratings),
                        'review_count': len(user_data),
                        'sentiment_trend': calculate_trend_simple(sentiments),
                        'rating_trend': calculate_trend_simple(ratings),
                        'sentiment_range': max(sentiments) - min(sentiments),
                        'rating_range': max(ratings) - min(ratings)
                    }
                    
                    user_features[user_id] = features
        
        print(f"   构建特征: {len(user_features)} 用户")
        
        # 准备聚类数据
        feature_matrix = []
        user_ids = []
        
        for user_id, features in user_features.items():
            feature_vector = [
                features['avg_sentiment'],
                features['sentiment_volatility'],
                features['avg_rating'],
                features['rating_volatility'],
                features['review_count'],
                features['sentiment_trend'],
                features['rating_trend'],
                features['sentiment_range']
            ]
            feature_matrix.append(feature_vector)
            user_ids.append(user_id)
        
        print(f"   特征矩阵: {len(feature_matrix)} × {len(feature_matrix[0])} ")
        
        # 数据标准化
        print("2. 数据标准化...")
        normalized_matrix = standardize_features(feature_matrix)
        
        # K-means聚类（改进版）
        print("3. 执行K-means聚类...")
        
        best_clusters = None
        best_inertia = float('inf')
        best_k = 3
        
        # 尝试不同的K值
        for k in range(2, 6):
            clusters, inertia = improved_kmeans(normalized_matrix, k=k, max_iter=10)
            print(f"   K={k}: inertia={inertia:.3f}")
            
            if inertia < best_inertia:
                best_inertia = inertia
                best_clusters = clusters
                best_k = k
        
        print(f"   最佳聚类: K={best_k}")
        
        # 分析聚类结果
        print("4. 分析聚类结果...")
        
        cluster_analysis = {}
        for cluster_id in range(best_k):
            cluster_indices = [i for i, c in enumerate(best_clusters) if c == cluster_id]
            cluster_features = [feature_matrix[i] for i in cluster_indices]
            
            if cluster_features:
                # 计算聚类中心
                cluster_center = [
                    sum(feature[j] for feature in cluster_features) / len(cluster_features)
                    for j in range(len(cluster_features[0]))
                ]
                
                cluster_analysis[f'cluster_{cluster_id}'] = {
                    'size': len(cluster_features),
                    'percentage': len(cluster_features) / len(feature_matrix) * 100,
                    'avg_sentiment': cluster_center[0],
                    'sentiment_volatility': cluster_center[1],
                    'avg_rating': cluster_center[2],
                    'rating_volatility': cluster_center[3],
                    'avg_review_count': cluster_center[4],
                    'sentiment_trend': cluster_center[5],
                    'rating_trend': cluster_center[6],
                    'sentiment_range': cluster_center[7]
                }
        
        # 聚类命名和解释
        cluster_names = assign_cluster_names(cluster_analysis)
        
        # 输出结果
        print("\n=== 用户聚类分析结果 ===")
        for cluster_id, analysis in cluster_analysis.items():
            name = cluster_names.get(cluster_id, "未命名群体")
            print(f"\n{cluster_id} - {name}:")
            print(f"  用户数量: {analysis['size']} ({analysis['percentage']:.1f}%)")
            print(f"  平均情绪: {analysis['avg_sentiment']:.3f}")
            print(f"  情绪波动: {analysis['sentiment_volatility']:.3f}")
            print(f"  平均评分: {analysis['avg_rating']:.3f}")
            print(f"  评论数量: {analysis['avg_review_count']:.1f}")
            print(f"  情绪趋势: {analysis['sentiment_trend']:.3f}")
        
        # 保存结果
        clustering_results = {
            'cluster_analysis': cluster_analysis,
            'cluster_names': cluster_names,
            'user_assignments': dict(zip(user_ids, best_clusters)),
            'methodology': {
                'features_used': ['avg_sentiment', 'sentiment_volatility', 'avg_rating', 
                                'rating_volatility', 'review_count', 'sentiment_trend', 
                                'rating_trend', 'sentiment_range'],
                'num_clusters': best_k,
                'sample_size': len(user_features)
            }
        }
        
        with open('advanced_clustering_results.json', 'w') as f:
            json.dump(clustering_results, f, indent=2, default=str)
        
        print(f"\n✅ 用户聚类分析完成，识别出{best_k}个用户群体")
        return clustering_results
        
    except Exception as e:
        print(f"❌ 聚类分析失败: {e}")
        return None

def calculate_std(values):
    """计算标准差"""
    if len(values) <= 1:
        return 0
    mean_val = sum(values) / len(values)
    variance = sum((x - mean_val) ** 2 for x in values) / len(values)
    return math.sqrt(variance)

def calculate_trend_simple(values):
    """计算简单趋势"""
    if len(values) <= 1:
        return 0
    return (values[-1] - values[0]) / len(values)

def standardize_features(matrix):
    """标准化特征矩阵"""
    if not matrix:
        return matrix
    
    num_features = len(matrix[0])
    standardized = []
    
    # 计算每个特征的均值和标准差
    for j in range(num_features):
        feature_values = [row[j] for row in matrix]
        mean_val = sum(feature_values) / len(feature_values)
        std_val = calculate_std(feature_values)
        
        if std_val == 0:
            std_val = 1  # 避免除零
        
        # 标准化
        for i, row in enumerate(matrix):
            if j == 0:
                standardized.append([])
            standardized[i].append((row[j] - mean_val) / std_val)
    
    return standardized

def improved_kmeans(data, k=3, max_iter=10):
    """改进版K-means聚类"""
    import random
    random.seed(42)
    
    if len(data) < k:
        return [0] * len(data), float('inf')
    
    # 初始化聚类中心
    centers = random.sample(data, k)
    
    for iteration in range(max_iter):
        # 分配点到最近中心
        clusters = []
        for point in data:
            distances = []
            for center in centers:
                dist = sum((point[i] - center[i]) ** 2 for i in range(len(point)))
                distances.append(dist)
            clusters.append(distances.index(min(distances)))
        
        # 更新中心
        new_centers = []
        for cluster_id in range(k):
            cluster_points = [data[i] for i in range(len(data)) if clusters[i] == cluster_id]
            if cluster_points:
                new_center = [
                    sum(point[j] for point in cluster_points) / len(cluster_points)
                    for j in range(len(cluster_points[0]))
                ]
                new_centers.append(new_center)
            else:
                new_centers.append(centers[cluster_id])
        
        centers = new_centers
    
    # 计算inertia
    total_inertia = 0
    for i, point in enumerate(data):
        center = centers[clusters[i]]
        inertia = sum((point[j] - center[j]) ** 2 for j in range(len(point)))
        total_inertia += inertia
    
    return clusters, total_inertia

def assign_cluster_names(cluster_analysis):
    """为聚类分配描述性名称"""
    names = {}
    
    for cluster_id, analysis in cluster_analysis.items():
        sentiment = analysis['avg_sentiment']
        volatility = analysis['sentiment_volatility']
        activity = analysis['avg_review_count']
        
        if activity >= 5:
            if sentiment >= 0.6 and volatility <= 0.3:
                name = "高活跃稳定积极型"
            elif sentiment >= 0.6 and volatility > 0.3:
                name = "高活跃波动积极型"
            else:
                name = "高活跃用户"
        elif sentiment >= 0.6:
            name = "积极情绪型"
        elif volatility > 0.4:
            name = "情绪波动型"
        else:
            name = "普通稳定型"
        
        names[cluster_id] = name
    
    return names

# 执行改进版聚类分析
clustering_results = advanced_user_clustering()
